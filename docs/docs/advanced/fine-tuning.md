---
sidebar_position: 13
---

# ğŸ¯ ç²¾è°ƒæŒ‡å—

## æ¦‚è¿°

Eliza æ”¯æŒå¤šç§ AI æ¨¡å‹æä¾›å•†ï¼Œå¹¶æä¾›å¹¿æ³›çš„é…ç½®é€‰é¡¹ï¼Œç”¨äºå¾®è°ƒæ¨¡å‹è¡Œä¸ºã€ç”ŸæˆåµŒå…¥å’Œä¼˜åŒ–æ€§èƒ½ã€‚

## æ¨¡å‹æä¾›å•†

Eliza é€šè¿‡çµæ´»çš„é…ç½®ç³»ç»Ÿæ”¯æŒå¤šç§æ¨¡å‹æä¾›å•†ï¼š

```typescript
enum ModelProviderName {
  OPENAI,
  ANTHROPIC,
  CLAUDE_VERTEX,
  GROK,
  GROQ,
  LLAMACLOUD,
  LLAMALOCAL,
  GOOGLE,
  REDPILL,
  OPENROUTER,
  HEURIST,
}
```

### æä¾›å•†é…ç½®

æ¯ä¸ªæä¾›å•†éƒ½æœ‰ç‰¹å®šçš„è®¾ç½®ï¼š

```typescript
const models = {
  [ModelProviderName.ANTHROPIC]: {
    settings: {
      stop: [],
      maxInputTokens: 200000,
      maxOutputTokens: 8192,
      frequency_penalty: 0.0,
      presence_penalty: 0.0,
      temperature: 0.3,
    },
    endpoint: "https://api.anthropic.com/v1",
    model: {
      [ModelClass.SMALL]: "claude-3-5-haiku",
      [ModelClass.MEDIUM]: "claude-3-5-sonnet-20241022",
      [ModelClass.LARGE]: "claude-3-5-opus-20240229",
    },
  },
  // ... å…¶ä»–æä¾›å•†
};
```

## æ¨¡å‹ç±»åˆ«

æ¨¡å‹æ ¹æ®å…¶èƒ½åŠ›åˆ†ä¸ºä¸åŒç±»åˆ«ï¼š

```typescript
enum ModelClass {
    SMALL,     // å¿«é€Ÿï¼Œé«˜æ•ˆå¤„ç†ç®€å•ä»»åŠ¡
    MEDIUM,    // æ€§èƒ½ä¸èƒ½åŠ›å¹³è¡¡
    LARGE,     // æœ€å¼ºå¤§ä½†è¾ƒæ…¢/æ›´æ˜‚è´µ
    EMBEDDING, // ä¸“ç”¨äºå‘é‡åµŒå…¥
    IMAGE      // å›¾åƒç”Ÿæˆèƒ½åŠ›
}
```

## åµŒå…¥ç³»ç»Ÿ

### é…ç½®

```typescript
const embeddingConfig = {
  dimensions: 1536,
  modelName: "text-embedding-3-small",
  cacheEnabled: true,
};
```

### å®ç°

```typescript
async function embed(runtime: IAgentRuntime, input: string): Promise<number[]> {
  // é¦–å…ˆæ£€æŸ¥ç¼“å­˜
  const cachedEmbedding = await retrieveCachedEmbedding(runtime, input);
  if (cachedEmbedding) return cachedEmbedding;

  // ç”Ÿæˆæ–°çš„åµŒå…¥
  const response = await runtime.fetch(
    `${runtime.modelProvider.endpoint}/embeddings`,
    {
      method: "POST",
      headers: {
        Authorization: `Bearer ${runtime.token}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        input,
        model: runtime.modelProvider.model.EMBEDDING,
        dimensions: 1536,
      }),
    },
  );

  const data = await response.json();
  return data?.data?.[0].embedding;
}
```

## ç²¾è°ƒé€‰é¡¹

### æ¸©åº¦æ§åˆ¶

é…ç½®æ¨¡å‹çš„åˆ›é€ æ€§ä¸ç¡®å®šæ€§ï¼š

```typescript
const temperatureSettings = {
  creative: {
    temperature: 0.8,
    frequency_penalty: 0.7,
    presence_penalty: 0.7,
  },
  balanced: {
    temperature: 0.5,
    frequency_penalty: 0.3,
    presence_penalty: 0.3,
  },
  precise: {
    temperature: 0.2,
    frequency_penalty: 0.0,
    presence_penalty: 0.0,
  },
};
```

### ä¸Šä¸‹æ–‡çª—å£

ç®¡ç†ä»¤ç‰Œé™åˆ¶ï¼š

```typescript
const contextSettings = {
  OPENAI: {
    maxInputTokens: 128000,
    maxOutputTokens: 8192,
  },
  ANTHROPIC: {
    maxInputTokens: 200000,
    maxOutputTokens: 8192,
  },
  LLAMALOCAL: {
    maxInputTokens: 32768,
    maxOutputTokens: 8192,
  },
};
```

## æ€§èƒ½ä¼˜åŒ–

### ç¼“å­˜ç­–ç•¥

```typescript
class EmbeddingCache {
  private cache: NodeCache;
  private cacheDir: string;

  constructor() {
    this.cache = new NodeCache({ stdTTL: 300 }); // 5 åˆ†é’Ÿ TTL
    this.cacheDir = path.join(__dirname, "cache");
  }

  async get(key: string): Promise<number[] | null> {
    // é¦–å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
    const cached = this.cache.get<number[]>(key);
    if (cached) return cached;

    // æ£€æŸ¥ç£ç›˜ç¼“å­˜
    return this.readFromDisk(key);
  }

  async set(key: string, embedding: number[]): Promise<void> {
    this.cache.set(key, embedding);
    await this.writeToDisk(key, embedding);
  }
}
```

### æ¨¡å‹é€‰æ‹©

```typescript
async function selectOptimalModel(
  task: string,
  requirements: ModelRequirements,
): Promise<ModelClass> {
  if (requirements.speed === "fast") {
    return ModelClass.SMALL;
  } else if (requirements.complexity === "high") {
    return ModelClass.LARGE;
  }
  return ModelClass.MEDIUM;
}
```

## æä¾›å•†ç‰¹å®šä¼˜åŒ–

### OpenAI

```typescript
const openAISettings = {
  endpoint: "https://api.openai.com/v1",
  settings: {
    stop: [],
    maxInputTokens: 128000,
    maxOutputTokens: 8192,
    frequency_penalty: 0.0,
    presence_penalty: 0.0,
    temperature: 0.6,
  },
  model: {
    [ModelClass.SMALL]: "gpt-4o-mini",
    [ModelClass.MEDIUM]: "gpt-4o",
    [ModelClass.LARGE]: "gpt-4o",
    [ModelClass.EMBEDDING]: "text-embedding-3-small",
    [ModelClass.IMAGE]: "dall-e-3",
  },
};
```

### Anthropic

```typescript
const anthropicSettings = {
  endpoint: "https://api.anthropic.com/v1",
  settings: {
    stop: [],
    maxInputTokens: 200000,
    maxOutputTokens: 8192,
    temperature: 0.3,
  },
  model: {
    [ModelClass.SMALL]: "claude-3-5-haiku",
    [ModelClass.MEDIUM]: "claude-3-5-sonnet-20241022",
    [ModelClass.LARGE]: "claude-3-5-opus-20240229",
  },
};
```

### æœ¬åœ° LLM

```typescript
const llamaLocalSettings = {
  settings: {
    stop: ["<|eot_id|>", "<|eom_id|>"],
    maxInputTokens: 32768,
    maxOutputTokens: 8192,
    repetition_penalty: 0.0,
    temperature: 0.3,
  },
  model: {
    [ModelClass.SMALL]: "NousResearch/Hermes-3-Llama-3.1-8B-GGUF",
    [ModelClass.MEDIUM]: "NousResearch/Hermes-3-Llama-3.1-8B-GGUF",
    [ModelClass.LARGE]: "NousResearch/Hermes-3-Llama-3.1-8B-GGUF",
    [ModelClass.EMBEDDING]: "togethercomputer/m2-bert-80M-32k-retrieval",
  },
};
```

### Heurist æä¾›å•†

```typescript
const heuristSettings = {
  settings: {
    stop: [],
    maxInputTokens: 32768,
    maxOutputTokens: 8192,
    repetition_penalty: 0.0,
    temperature: 0.7,
  },
  imageSettings: {
    steps: 20,
  },
  endpoint: "https://llm-gateway.heurist.xyz",
  model: {
    [ModelClass.SMALL]: "hermes-3-llama3.1-8b",
    [ModelClass.MEDIUM]: "mistralai/mixtral-8x7b-instruct",
    [ModelClass.LARGE]: "nvidia/llama-3.1-nemotron-70b-instruct",
    [ModelClass.EMBEDDING]: "", // ç¨åæ·»åŠ 
    [ModelClass.IMAGE]: "FLUX.1-dev",
  },
};
```

## æµ‹è¯•ä¸éªŒè¯

### åµŒå…¥æµ‹è¯•

```typescript
async function validateEmbedding(
  embedding: number[],
  expectedDimensions: number = 1536,
): Promise<boolean> {
  if (!Array.isArray(embedding)) return false;
  if (embedding.length !== expectedDimensions) return false;
  if (embedding.some((n) => typeof n !== "number")) return false;
  return true;
}
```

### æ¨¡å‹æ€§èƒ½æµ‹è¯•

```typescript
async function benchmarkModel(
  runtime: IAgentRuntime,
  modelClass: ModelClass,
  testCases: TestCase[],
): Promise<BenchmarkResults> {
  const results = {
    latency: [],
    tokenUsage: [],
    accuracy: [],
  };

  for (const test of testCases) {
    const start = Date.now();
    const response = await runtime.generateText({
      context: test.input,
      modelClass,
    });
    results.latency.push(Date.now() - start);
    // ... å…¶ä»–æŒ‡æ ‡
  }

  return results;
}
```

## æœ€ä½³å®è·µ

### æ¨¡å‹é€‰æ‹©æŒ‡å—

1. **ä»»åŠ¡å¤æ‚æ€§**

   - ç®€å•ã€å¿«é€Ÿå“åº”ä½¿ç”¨ SMALL
   - æ€§èƒ½å¹³è¡¡ä½¿ç”¨ MEDIUM
   - å¤æ‚æ¨ç†ä½¿ç”¨ LARGE

2. **ä¸Šä¸‹æ–‡ç®¡ç†**

   - ä¿æŒæç¤ºç®€æ´å’Œé›†ä¸­
   - é«˜æ•ˆä½¿ç”¨ä¸Šä¸‹æ–‡çª—å£
   - å®æ–½é€‚å½“çš„ä¸Šä¸‹æ–‡æˆªæ–­

3. **æ¸©åº¦è°ƒæ•´**
   - äº‹å®æ€§å“åº”ä½¿ç”¨è¾ƒä½æ¸©åº¦
   - åˆ›æ„ä»»åŠ¡ä½¿ç”¨è¾ƒé«˜æ¸©åº¦
   - æ ¹æ®ä½¿ç”¨åœºæ™¯å¹³è¡¡

### æ€§èƒ½ä¼˜åŒ–

1. **ç¼“å­˜ç­–ç•¥**

   - ä¸ºé¢‘ç¹è®¿é—®çš„å†…å®¹ç¼“å­˜åµŒå…¥
   - å®æ–½åˆ†å±‚ç¼“å­˜ï¼ˆå†…å­˜/ç£ç›˜ï¼‰
   - å®šæœŸæ¸…ç†ç¼“å­˜

2. **èµ„æºç®¡ç†**
   - ç›‘æ§ä»¤ç‰Œä½¿ç”¨æƒ…å†µ
   - å®æ–½é€Ÿç‡é™åˆ¶
   - ä¼˜åŒ–æ‰¹å¤„ç†

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ä»¤ç‰Œé™åˆ¶**

   ```typescript
   function handleTokenLimit(error: Error) {
     if (error.message.includes("token limit")) {
       return truncateAndRetry();
     }
   }
   ```

2. **åµŒå…¥é”™è¯¯**

   ```typescript
   function handleEmbeddingError(error: Error) {
     if (error.message.includes("dimension mismatch")) {
       return regenerateEmbedding();
     }
   }
   ```

3. **æ¨¡å‹å¯ç”¨æ€§**
   ```typescript
   async function handleModelFailover(error: Error) {
     if (error.message.includes("model not available")) {
       return switchToFallbackModel();
     }
   }
   ```

---